#0. Load Required Libraries
#test1
import pandas as pd
from pandas import read_csv
from pandas.plotting import scatter_matrix
import matplotlib as mpl
mpl.use('TkAgg')
from matplotlib import pyplot
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
import seaborn as sns
import matplotlib.pyplot as plt
import missingno as msno
from sklearn.impute import SimpleImputer
import category_encoders as ce 


#1. Load Data
data_train_url = "C:/Users/cesar/OneDrive/Documents/CS/DL-Projects/MalwareDetection/iiitb-ml-malware-detection-tanmay/Malware_train.csv" 
data_test_url  = "C:/Users/cesar/OneDrive/Documents/CS/DL-Projects/MalwareDetection/iiitb-ml-malware-detection-tanmay/Malware_test.csv"

data_train = pd.read_csv(data_train_url, low_memory=False)
data_test = pd.read_csv(data_test_url, low_memory=False)


#2. Data Exploration & Cleaning

data_train_shape = data_train.shape 

#Columns to Drop: Too many NaNs / Unbalanced / Etc
# "ProductName", "IsSxsPassiveMode", "AVProductsEnabled", "HasTpm", "Platform", "OsVer",
# "AutoSampleOptIn","PuaMode","SMode", "Firewall", "UacLuaenable","Census_DeviceFamily", "Census_ProcessorManufacturerIdentifier", "Census_PrimaryDiskTotalCapacity", "Census_SystemVolumeTotalCapacity", 
# "Census_InternalBatteryNumberOfCharges" , "Census_InternalBatteryType", "Census_IsPortableOperatingSystem","Census_IsFlightingInternal", "Census_InternalPrimaryDiagonalDisplaySizeInInches",
# "Census_InternalPrimaryDisplayResolutionHorizontal", "Census_InternalPrimaryDisplayResolutionVertical", "Census_IsFlightsDisabled", "Census_ThresholdOptIn", "Census_IsVirtualDevice", "Census_IsTouchEnabled", 
# "Census_IsPenCapable",'Census_OSSkuName',"Census_FlightRing","Census_IsWIMBootEnabled","Census_IsAlwaysOnAlwaysConnectedCapable", "Wdft_IsGamer"

ft2drop = ["MachineIdentifier", "ProductName", "IsSxsPassiveMode", "AVProductsEnabled", "HasTpm", "Platform", "OsVer",
    "AutoSampleOptIn","PuaMode","SMode", "Firewall", "UacLuaenable","Census_DeviceFamily", "SmartScreen", "Census_ProcessorManufacturerIdentifier",
    "Census_PrimaryDiskTotalCapacity", "Census_SystemVolumeTotalCapacity", "Census_InternalBatteryNumberOfCharges" , "Census_InternalBatteryType", "Census_IsPortableOperatingSystem",
    "Census_IsFlightingInternal", "Census_InternalPrimaryDiagonalDisplaySizeInInches","Census_InternalPrimaryDisplayResolutionHorizontal", "Census_InternalPrimaryDisplayResolutionVertical", 
    "Census_IsFlightsDisabled", "Census_ThresholdOptIn", "Census_IsVirtualDevice", "Census_IsTouchEnabled", "Census_IsPenCapable",'Census_OSSkuName',"Census_FlightRing","Census_IsWIMBootEnabled","Census_IsAlwaysOnAlwaysConnectedCapable", "Wdft_IsGamer"]

#Remove selected features (Too many NaNs / Unbalanced / Etc) from train and test data
df_train_filtdrop = data_train.drop(ft2drop, axis=1)
df_test_filtdrop = data_test.drop(ft2drop, axis=1)


#Taking Care of Remaining Features 
#Remaining Columns after filtering 
# ['EngineVersion', 'AppVersion', 'AvSigVersion', 'IsBeta', 'RtpStateBitfield', 'AVProductStatesIdentifier', 'AVProductsInstalled', 'CountryIdentifier', 'CityIdentifier', 'GeoNameIdentifier', 'LocaleEnglishNameIdentifier',
#  'Processor', 'OsBuild', 'OsSuite', 'OsPlatformSubRelease', 'OsBuildLab', 'SkuEdition', 'IsProtected', 'IeVerIdentifier', 'Census_MDC2FormFactor', 'Census_OEMNameIdentifier', 'Census_OEMModelIdentifier', 'Census_ProcessorCoreCount', 
#  'Census_ProcessorModelIdentifier', 'Census_PrimaryDiskTypeName', 'Census_HasOpticalDiskDrive', 'Census_TotalPhysicalRAM', 'Census_ChassisTypeName', 'Census_PowerPlatformRoleName', 'Census_OSVersion', 'Census_OSArchitecture', 'Census_OSBranch',
#  'Census_OSBuildNumber', 'Census_OSBuildRevision', 'Census_OSEdition', 'Census_OSInstallTypeName', 'Census_OSInstallLanguageIdentifier', 'Census_OSUILocaleIdentifier', 'Census_OSWUAutoUpdateOptionsName',
#  'Census_GenuineStateName', 'Census_ActivationChannel', 'Census_FirmwareManufacturerIdentifier', 'Census_FirmwareVersionIdentifier', 'Census_IsSecureBootEnabled', 'Wdft_RegionIdentifier', 'HasDetections']


# Drop Columns with more than 25% NaN from Train and Test Data
df_train_filtdrop = df_train_filtdrop.dropna(axis=1, thresh=len(df_train_filtdrop)*0.25)
df_test_filtdrop  =  df_test_filtdrop.dropna(axis=1, thresh=len(df_test_filtdrop)*0.25)

print(df_train_filtdrop.describe())

#TODO:Take Care of Remaining NaNs in columns with certain NaN # - Impute

# Numerical Variables
    #RtpStateBitfield
    #AVProductStatesIdentifier
    #AVProductsInstalled
    #Census_ProcessorCoreCount 
    #Census_TotalPhysicalRAM


#Taking care of Categorical Variables - Ordinal Variables
    #EngineVersion
    #AppVersion
    #AvSigVersion
    #AvSigVersion
    #OsVersion
    #OsBuild
    #SmartScreen
    #Census_ProcessorClass
    #Census_ProcessorClass
    #Census_OSBuildNumber
    #Census_OSBuildRevision


#Processor - OneHotEncoder - which variables to create Bins? from
    #CountryIdentifier
    #CityIdentifier
    #OrganizationIdentifier
    #GeoNameIdentifier
    #LocaleEnglishNameIdentifier  
    #Processor
    #OSSuite
    #OsPlatformSubRelease
    #OSBuildLab
    #SkuEdition
    #Census_MDC2FormFactor
    #Census_OEMModelIdentifier
    #Census_ProcessorModelIdentifier
    #Census_PrimaryDiskTypeName
    #Census_ChassisTypeName
    #Census_PowerPlatformRoleName
    #Census_OSArchitecture
    #Census_OSBranch
    #Census_OSEdition
    #Census_OSInstallTypeName
    #Census_OSInstallLanguageIdentifier
    #Census_OSUILocaleIdentifier
    #Census_OSWUAutoUpdateOptionsName
    #Census_GenuineStateName
    #Census_ActivationChannel
    #Census_FirmawareManufacturerIdentifier
    #Census_FirmawareVersionIdentifier
    #Wdft_RegionIdentifier

# Yes/ No
    #IsBeta
    #IsProtected 
    #IsVerIdentifier
    #Census_HasOpticalDiskDrive
    #Census_IsSecureBootEnabled
    
# y = hasDetections


print('train Data Cols Shape: ', data_train.shape)
print("Data train shape: ", data_train.columns.values.tolist())

print('train Data filtered Cols Shape: ', df_train_filtdrop.shape)
print("remaining features after filtering: ", df_train_filtdrop.columns.values.tolist())



ctg_ft = (df_train_filtdrop.dtypes == 'object')
ob_fts = list(ctg_ft[ctg_ft].index)
print("categorical variables:")
print(ob_fts)

print(df_train_filtdrop.dtypes)

#cat_encoder = ce.BinaryEncoder(cols=ob_fts)
#cat_cols_train = cat_encoder.fit(data_train[ob_fts])
#cat_cols_train.index = data_train.index 

#data_train = data_train.drop(ob_fts, axis = 1)
#data_train = pd.concat([data_train,cat_cols_train], axis=1)

#y = data_train.HasDetections
#data_train = data_train.drop(data_train["HasDetections"], axis=1)

#print(data_train.head())                                    #Get preliminary info of the available data

#missing_val_count_by_column = (data_train.isnull().sum())   #Get number of misssing values per feature 
#print(missing_val_count_by_column[missing_val_count_by_column > 0])

#Lets start by getting rid of columns with more than 15% of missing values and Imputing the rest
#tresh_data = len(data_train) * 0.80 
#data_train_filt = data_train.dropna(thresh=tresh_data, axis=1)

#missing_val_count_by_column = (data_train_filt.isnull().sum())   #Get number of misssing values per feature 
#print(missing_val_count_by_column[missing_val_count_by_column > 0])

#print(data_train_filt.head())  

#Impute Remaining columns with NaN 
#TODO: Take Care of Categorical Variables and assemble last Filtered+Imputed Train Data Frame
#my_imputer = SimpleImputer()
#numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
#train_filt_imputed = pd.DataFrame(my_imputer.fit_transform(data_train_filt.select_dtypes(include=numerics)))

#Get Remaining column with NaNs
#missing_val_count_by_column = (train_filt_imputed.isnull().sum())   #Get number of misssing values per feature 
#print(missing_val_count_by_column[missing_val_count_by_column > 0])

#print(train_filt_imputed.describe())

#print(train_filt_imputed.columns.values)





#3. Feature Selection
#TODO: Find features that influence the model

#4. Building the Model

    #4.1 Decision Tree 


    #4.2 Gradient Boosting


    #4.3 AdaBoost  



#5. Model Performance 
   

#data_train.info(verbose=True)

#Check numeric columns
#numeric_cols = data_train.select_dtypes(include=['number']).columns
#print(numeric_cols)

#Check non-numeric columns
#non_numeric_cols = data_train.select_dtypes(exclude=['number']).columns
#print(non_numeric_cols)

#Mising Data - Non Numeric 
#data_train[non_numeric_cols].info()

#Missing Data - Numeric
#num_missing = data_train.isna().sum()
#print(num_missing[:10])

################################
###   MISSING DATA HEATMAP   ### 
################################

#plt.figure(figsize=(10,8))
#
#cols = data_train.columns[:30]
#colours = ['#000099', '#ffff00'] # specify colours: yellow - missing. blue - not missing
#sns.heatmap(data_train[cols].isna(), cmap=sns.color_palette(colours))
#plt.show()

#msno.matrix(data_train.iloc[:, :30])

#TO-DO: Missing Data 
#TO-DO: Outliers
#TO-DO: Unnecessary
#TO-DO: Variables to Infere

